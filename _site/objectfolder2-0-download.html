<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta charset="utf-8">

  <!-- Page Info -->
  <link rel="shortcut icon" href="/assets/img/objectfolder_logo.png">
  <title>Download Instruction of ObjectFolder 2.0 – ObjectFolder</title>
  <meta name="description" content="">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title"
    content="Download Instruction of ObjectFolder 2.0 – ObjectFolder">
  <meta name="twitter:description" content="">
  <meta name="twitter:image:src" content="">

  <!-- Facebook OpenGraph -->
  <meta property="og:title"
    content="Download Instruction of ObjectFolder 2.0 – ObjectFolder" />
  <meta property="og:description" content="" />
  <meta property="og:image" content="" />

  <!--  Fonts and icons -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700" rel="stylesheet">
  <link href="https://use.fontawesome.com/releases/v5.0.6/css/all.css" rel="stylesheet">
  <!-- Nucleo Icons -->
  <link href="/assets/css/nucleo-icons.css" rel="stylesheet" />
  <link href="/assets/css/nucleo-svg.css" rel="stylesheet" />
  <!-- Font Awesome Icons -->
  <link href="/assets/css/font-awesome.css" rel="stylesheet" />
  <link href="/assets/css/nucleo-svg.css" rel="stylesheet" />
  <!-- CSS Files -->
  <link rel="stylesheet" href="/assets/styles/styles.css" rel="stylesheet">

  

  

</head>

<body>
  
      <nav id="navbar-main" class="navbar navbar-main navbar-expand-lg bg-white headroom">
        

        <div class="container">
          
          <a href="/" class="navbar-brand mr-lg-5">
            <img src="/assets/img/objectfolder_logo_2.png">
          </a>
          

          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar_global"
            aria-controls="navbar_global" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="navbar-collapse collapse" id="navbar_global">
            <div class="navbar-collapse-header">
              <div class="row">
                <div class="col-6 collapse-brand">
                  
                  <a href="/">
                    <img src="/assets/img/objectfolder_logo_2.png">
                  </a>
                  
                </div>
                <div class="col-6 collapse-close">
                  <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar_global"
                    aria-controls="navbar_global" aria-expanded="false" aria-label="Toggle navigation">
                    <span></span>
                    <span></span>
                  </button>
                </div>
              </div>
            </div>
            <ul class="navbar-nav navbar-nav-hover align-items-lg-center ml-lg-auto">
              
                
                  <li class="nav-item">
                    <a href="/" class="nav-link">
                      <span class="nav-link-inner--text">Home</span>
                    </a>
                  </li>
                
              
                
                  <li class="nav-item dropdown">
                    <a href="javascript:;" class="nav-link" data-toggle="dropdown" role="button">
                      <span class="nav-link-inner--text">ObjectFolder-Real</span>
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                      
                      <a class="dropdown-item" href="/objectfolder-real-download">
                        <i class="ni "></i>
                        Download
                      </a>
                      
                      <a class="dropdown-item" href="/objectfolder-real">
                        <i class="ni "></i>
                        Interactive Demos
                      </a>
                      
                      <a class="dropdown-item" href="/explore-samples">
                        <i class="ni "></i>
                        Explore Samples
                      </a>
                      
                    </div>
                  </li>
                
              
                
                  <li class="nav-item dropdown">
                    <a href="javascript:;" class="nav-link" data-toggle="dropdown" role="button">
                      <span class="nav-link-inner--text">ObjectFolder 2.0</span>
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                      
                      <a class="dropdown-item" href="/objectfolder2-0-download">
                        <i class="ni "></i>
                        Download
                      </a>
                      
                      <a class="dropdown-item" href="https://github.com/rhgao/ObjectFolder">
                        <i class="ni "></i>
                        Code
                      </a>
                      
                      <a class="dropdown-item" href="https://www.youtube.com/watch?v=e5aToT3LkRA">
                        <i class="ni "></i>
                        Supplementary Video
                      </a>
                      
                    </div>
                  </li>
                
              
                
                  <li class="nav-item dropdown">
                    <a href="javascript:;" class="nav-link" data-toggle="dropdown" role="button">
                      <span class="nav-link-inner--text">Benchmarks</span>
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                      
                      <a class="dropdown-item" href="https://github.com/objectfolder">
                        <i class="ni "></i>
                        Code
                      </a>
                      
                      <a class="dropdown-item" href="/benchmark-recognition">
                        <i class="ni "></i>
                        Object Recognition
                      </a>
                      
                      <a class="dropdown-item" href="/benchmark-reconstruction">
                        <i class="ni "></i>
                        Object Reconstruction
                      </a>
                      
                      <a class="dropdown-item" href="/benchmark-manipulation">
                        <i class="ni "></i>
                        Object Manipulation
                      </a>
                      
                    </div>
                  </li>
                
              

            </ul>
          </div>
        </div>
      </nav>

  <div class="wrapper page">
    
    <!-- Is not a blog post or blog archive or contact page -->
    
    <!-- Is a page without a banner -->
    <div class="container contentWrapper pb-2">
      <div class="text-left mt-5 mb-3">
        <h3 class="display-2">Download Instruction of ObjectFolder 2.0</h3>
        
      </div>
    </div>
    
    

    <div id="main" class="container">
      <h3 id="about-objectfolder-20">About ObjectFolder 2.0</h3>

<p>ObjectFolder 2.0 is a dataset of 1,000 objects in the form of implicit representations. It contains 1,000 Object Files each containing the complete multisensory profile for an object instance. Each Object File implicit neural representation network contains three sub-networks—VisionNet, AudioNet, and TouchNet, which through querying with the corresponding extrinsic parameters we can obtain the visual appearance of the object from different views and lighting conditions, impact sounds of the object at each position of specified force profile, and tactile sensing of the object at every surface location for varied rotation angels and pressing depth, respectively. The dataset contains common household objects of diverse categories such as wood desks, ceramic bowls, plastic toys, steel forks, glass mirrors, etc. The objects.csv file contains the metadata for these 1,000 objects. Note that the first 100 objects are the same as ObjectFolder 1.0, and we recommend using the new version for improved multisensory simulation and implicit representation for the objects. See the paper for details.</p>

<h3 id="prerequisites">Prerequisites</h3>
<ul>
  <li>OS: Ubuntu 20.04.2 LTS</li>
  <li>GPU: &gt;= NVIDIA GTX 1080 Ti with &gt;= 460.73.01 driver</li>
  <li>Python package manager <code class="language-plaintext highlighter-rouge">conda</code></li>
</ul>

<h3 id="setup">Setup</h3>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/rhgao/ObjectFolder.git
<span class="nb">cd </span>ObjectFolder
<span class="nb">export </span><span class="nv">OBJECTFOLDER_HOME</span><span class="o">=</span><span class="nv">$PWD</span>
conda <span class="nb">env </span>create <span class="nt">-f</span> <span class="nv">$OBJECTFOLDER_HOME</span>/environment.yml
<span class="nb">source </span>activate ObjectFolder-env
</code></pre></div></div>

<h3 id="dataset-download-and-preparation">Dataset Download and Preparation</h3>
<p>Use the following command to download the first 100 objects:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://download.cs.stanford.edu/viscam/ObjectFolder/ObjectFolder1-100.tar.gz
<span class="nb">tar</span> <span class="nt">-xvf</span> ObjectFolder1-100.tar.gz
</code></pre></div></div>
<p>Use the following command to download ObjectFiles with KiloOSF that supports real-time visual rendering at the expense of larger model size:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://download.cs.stanford.edu/viscam/ObjectFolder/ObjectFolder1-100KiloOSF.tar.gz
<span class="nb">tar</span> <span class="nt">-xvf</span> ObjectFolder101-100KiloOSF.tar.gz
</code></pre></div></div>
<p>Similarly, use the following command to download objects from 101-1000:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://download.cs.stanford.edu/viscam/ObjectFolder/ObjectFolder[X+1]-[X+100].tar.gz
wget https://download.cs.stanford.edu/viscam/ObjectFolder/ObjectFolder[X+1]-[X+100]KiloOSF.tar.gz
<span class="nb">tar</span> <span class="nt">-xvf</span> ObjectFolder[X+1]-[X+100].tar.gz
<span class="nb">tar</span> <span class="nt">-xvf</span> ObjectFolder[X+1]-[X+100]KiloOSF.tar.gz
<span class="c"># replace X with a value in [100,200,300,400,500,600,700,800,900]</span>
</code></pre></div></div>

<h3 id="rendering-visual-acoustic-and-tactile-sensory-data">Rendering Visual, Acoustic, and Tactile Sensory Data</h3>
<p>Run the following command to render visual appearance of the object from a specified camera viewpoint and lighting direction:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>python OF_render.py <span class="nt">--modality</span> vision <span class="nt">--object_file_path</span> path_of_ObjectFile <span class="se">\</span>
      <span class="nt">--vision_test_file_path</span> path_of_vision_test_file <span class="se">\</span>
      <span class="nt">--vision_results_dir</span> path_of_vision_results_directory <span class="se">\</span>
</code></pre></div></div>
<p>Run the following command to render impact sounds of the object at a specified surface location and impact force:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>python OF_render.py <span class="nt">--modality</span> audio <span class="nt">--object_file_path</span> path_of_ObjectFile <span class="se">\</span>
      <span class="nt">--audio_vertices_file_path</span> path_of_audio_testing_vertices_file <span class="se">\</span>
      <span class="nt">--audio_forces_file_path</span> path_of_forces_file <span class="se">\</span>
      <span class="nt">--audio_results_dir</span> path_of_audio_results_directory <span class="se">\</span>
</code></pre></div></div>
<p>Run the following command to render tactile RGB iamges of the object at a specified surface location, gel rotation angle, and deformation:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>python OF_render.py <span class="nt">--modality</span> <span class="nb">touch</span> <span class="nt">--object_file_path</span> path_of_ObjectFile <span class="se">\</span>
      <span class="nt">--touch_vertices_file_path</span> path_of_touch_testing_vertices_file <span class="se">\</span>
      <span class="nt">--touch_gelinfo_file_path</span> path_of_gelinfor_file <span class="se">\</span>
      <span class="nt">--touch_results_path</span> path_of_touch_results_directory
</code></pre></div></div>
<p>The command-line arguments are described as follows:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">--object_file_path</code>: The path of ObjectFile.</li>
  <li><code class="language-plaintext highlighter-rouge">--vision_test_file_path</code>: The path of the testing file for vision, which should be a npy file.</li>
  <li><code class="language-plaintext highlighter-rouge">--vision_results_dir</code>: The path of the vision results directory to save rendered images.</li>
  <li><code class="language-plaintext highlighter-rouge">--audio_vertices_file_path</code>: The path of the testing vertices file for audio, which should be a npy file.</li>
  <li><code class="language-plaintext highlighter-rouge">--audio_forces_file_path</code>: The path of forces file for audio, which should be a npy file.</li>
  <li><code class="language-plaintext highlighter-rouge">--audio_results_dir</code>: The path of audio results directory to save rendered impact sounds as .wav files.</li>
  <li><code class="language-plaintext highlighter-rouge">--touch_vertices_file_path</code>: The path of the testing vertices file for touch, which should be a npy file.</li>
  <li><code class="language-plaintext highlighter-rouge">--touch_gelinfo_file_path</code>: The path of the gelinfo file for touch that speficifies the gel rotation angle and deformation depth, which should be a npy file.</li>
  <li><code class="language-plaintext highlighter-rouge">--touch_results_dir</code>: The path of the touch results directory to save rendered tactile RGB images.</li>
</ul>

<h3 id="data-format">Data Format</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">--vision_test_file_path</code>: It is a npy file with shape of (N, 6), where N is the number of testing viewpoints. Each data point contains the coordinates of the camera and the light in the form of (camera_x, camera_y, camera_z, light_x, light_y, light_z).</li>
  <li><code class="language-plaintext highlighter-rouge">--audio_vertices_file_path</code>: It is a npy file with shape of (N, 3), where N is the number of testing vertices. Each data point represents a coordinate on the object in the form of (x, y, z).</li>
  <li><code class="language-plaintext highlighter-rouge">--audio_forces_file_path</code>: It is a npy file with shape of (N, 3), where N is the number of testing vertices. Each data point represents the force values for the corresponding impact in the form of (F_x, F_y, F_z).</li>
  <li><code class="language-plaintext highlighter-rouge">--touch_vertices_file_path</code>: It is a npy file with shape of (N, 3), where N is the number of testing vertices. Each data point contains a coordinate on the object in the form of (x, y, z).</li>
  <li><code class="language-plaintext highlighter-rouge">--touch_gelinfo_file_path</code>: It is a npy file with shape of (N, 3), where N is the number of testing vertices. Each data point contains the gel rotation angle and gel displacement in the form of (theta, phi, depth). theta is in the range of [0, np.radians(15)], phi is in the range of [0, 2pi], and depth is in the range of [0.0005,0.002].</li>
</ul>

<h3 id="objectfile-with-kiloosf-for-real-time-visual-rendering">ObjectFile with KiloOSF for Real-time Visual Rendering</h3>
<p>To use KiloOSF, please make a copy of <a href="https://github.com/creiser/kilonerf/tree/master/cuda">cuda</a> in the root directory of this repo and follow the steps in <a href="https://github.com/creiser/kilonerf">CUDA extension installation</a>. Run the following command to render visual appearance of the object from a specified camera viewpoint and lighting direction:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>python OF_render.py <span class="nt">--modality</span> vision <span class="nt">--KiloOSF</span> <span class="nt">--object_file_path</span> path_of_KiloOSF_ObjectFile <span class="se">\</span>
      <span class="nt">--vision_test_file_path</span> path_of_vision_test_file <span class="se">\</span>
      <span class="nt">--vision_results_dir</span> path_of_vision_results_directory <span class="se">\</span>
</code></pre></div></div>

<h3 id="demo">Demo</h3>
<p>Below we show an example of rendering the visual, acoustic, and tactile data from the ObjectFile implicit representation for one object:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>python OF_render.py <span class="nt">--modality</span> vision,audio,touch <span class="nt">--object_file_path</span> demo/ObjectFile.pth <span class="se">\</span>
      <span class="nt">--vision_test_file_path</span> demo/vision_demo.npy <span class="se">\</span>
      <span class="nt">--vision_results_dir</span> demo/vision_results/ <span class="se">\</span>
      <span class="nt">--audio_vertices_file_path</span> demo/audio_demo_vertices.npy <span class="se">\</span>
      <span class="nt">--audio_forces_file_path</span> demo/audio_demo_forces.npy <span class="se">\</span>
      <span class="nt">--audio_results_dir</span> demo/audio_results/ <span class="se">\</span>
      <span class="nt">--touch_vertices_file_path</span> demo/touch_demo_vertices.npy <span class="se">\</span>
      <span class="nt">--touch_gelinfo_file_path</span> demo/touch_demo_gelinfo.npy <span class="se">\</span>
      <span class="nt">--touch_results_dir</span> demo/touch_results/
</code></pre></div></div>
<p>The rendered images, impact sounds, tactile images will be saved in <code class="language-plaintext highlighter-rouge">demo/vision_results/</code>, <code class="language-plaintext highlighter-rouge">demo/audio_results/</code>, and <code class="language-plaintext highlighter-rouge">demo/touch_results/</code>, respectively.</p>

<h3 id="publications">Publications</h3>
<p>If you find our dataset, code or project useful in your research, we appreciate it if you could cite:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{gao2022ObjectFolderV2,
  title = {ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer},
  author = {Gao, Ruohan and Si, Zilin and Chang, Yen-Yu and Clarke, Samuel and Bohg, Jeannette and Fei-Fei, Li and Yuan, Wenzhen and Wu, Jiajun},
  booktitle = {CVPR},
  year = {2022}
}

@inproceedings{gao2021ObjectFolder,
  title = {ObjectFolder: A Dataset of Objects with Implicit Visual, Auditory, and Tactile Representations},
  author = {Gao, Ruohan and Chang, Yen-Yu and Mall, Shivani and Fei-Fei, Li and Wu, Jiajun},
  booktitle = {CoRL},
  year = {2021}
}
</code></pre></div></div>

<h3 id="license">License</h3>
<p>ObjectFolder is CC BY 4.0 licensed, as found in the LICENSE file. The mesh files for the 1,000 high quality 3D objects originally come from online repositories including: <a href="https://amazon-berkeley-objects.s3.amazonaws.com/index.html">ABO dataset</a>, <a href="https://3dmodelhaven.com/">3D Model Haven</a>, <a href="http://ycb-benchmarks.s3-website-us-east-1.amazonaws.com/">YCB dataset</a>, and <a href="https://app.ignitionrobotics.org/GoogleResearch/fuel/collections/Google\%20Scanned\%20Objects">Google Scanned Objects</a>. Please also refer to their original lisence file. We appreciate their sharing of these great object assets.</p>

    </div>
  </div>


  <footer class="footer mt-5 pt-4">
  <div class="container">
    <div class="row row-grid align-items-center mb-2 mt-2">
      <div class="col-lg-12">
        <h5 class="mb-0 font-weight-light"><img class="ml-lg-5" src="/assets/img/svl_logo3.png" height="100px" >
          ObjectFolder is developed by the Stanford Vision and Learning Lab and collaborators.</h5>
      </div>
      <!-- <div class="col-lg-2 text-lg-right">
        
    

    

    

    

    

    

    

    

    

    
    <button onclick="location.href='https://github.com/StanfordVL/behavior';" rel="nofollow" class="btn btn-icon-only btn-github rounded-circle" data-toggle="tooltip" data-original-title="Github">
        <span class="btn-inner--icon">
            <i class="fab fa-github" aria-hidden="true"></i>
        </span>
    </button>
    

    

    

      </div> -->
    </div>
    <hr>
    <div class="row align-items-center justify-content-md-between">
      <div class="col-md-6">
        <div class="copyright">
          <span> © 2023 <a href="http://svl.stanford.edu/" target="_blank">Stanford Vision and Learning Lab</a> </span>
        </div>
      </div>
      <!-- <div class="col-md-6">
        <ul class="nav nav-footer justify-content-end">
          
          
          <li class="nav-item">
            <a href="/" class="nav-link">
              <span class="nav-link-inner--text">Home</span>
            </a>
          </li>
          
          
          

          
          
          

          
          
          

          
          
        </ul>
      </div> -->
    </div>
  </div>
</footer>



<!--   Core JS Files   -->
<script src="/assets/js/core/jquery.min.js" type="text/javascript"></script>
<script src="/assets/js/core/popper.min.js" type="text/javascript"></script>
<script src="/assets/js/core/bootstrap.min.js" type="text/javascript"></script>
<script src="/assets/js/plugins/perfect-scrollbar.jquery.min.js"></script>
<!--  Plugin for Switches, full documentation here: http://www.jque.re/plugins/version3/bootstrap.switch/ -->
<script src="/assets/js/plugins/bootstrap-switch.js"></script>
<!--  Plugin for the Sliders, full documentation here: http://refreshless.com/nouislider/ -->
<script src="/assets/js/plugins/nouislider.min.js" type="text/javascript"></script>
<!--  Plugin for the Carousel, full documentation here: http://jedrzejchalubek.com/ -->
<script src="/assets/js/plugins/glide.js" type="text/javascript"></script>
<!--  Plugin for the DatePicker, full documentation here: https://flatpickr.js.org/ -->
<script src="/assets/js/plugins/moment.min.js"></script>
<!--	Plugin for Select, full documentation here: https://joshuajohnson.co.uk/Choices/ -->
<script src="/assets/js/plugins/choices.min.js" type="text/javascript"></script>
<!--  Plugin for the DateTimePicker, full documentation here: https://flatpickr.js.org/ -->
<script src="/assets/js/plugins/datetimepicker.js" type="text/javascript"></script>
<!-- Plugin for Fileupload, full documentation here: http://www.jasny.net/bootstrap/javascript/#fileinput -->
<script src="/assets/js/plugins/jasny-bootstrap.min.js"></script>
<!-- Plugin for Headrom, full documentation here: https://wicky.nillia.ms/headroom.js/ -->
<script src="/assets/js/plugins/headroom.min.js"></script>
<!-- Control Center for Argon UI Kit: parallax effects, scripts for the example pages etc -->

<script>
  // Blog Post Carousel
  if (document.querySelector('.blogGlide') !== null) {
    new Glide('.blogGlide', {
      type: 'carousel',
      startAt: 0,
      focusAt: 2,
      perTouch: 1,
      perView: 4
    }).mount();
  }

  if (document.querySelector('.glide') !== null) {
    // Generic
     new Glide('.glide', {
      type: 'carousel',
      startAt: 0,
      focusAt: 2,
      perTouch: 1,
      perView: 4
    }).mount();
  }

  if (document.querySelector('.testimonial-glide') !== null) {
    // Testimonial Carousel
    new Glide('.testimonial-glide', {
      type: 'carousel',
      startAt: 0,
      focusAt: 2,
      perTouch: 1,
      perView: 4
    }).mount();
  }

</script>

<script>
  $(function () {
    var navOffset = $('#navbar-main').height();
    $('.contentWrapper').css('padding-top', navOffset * 2 + 'px');
  });    
</script>



<script src="/assets/js/argon-design-system.min.js?v=1.0.0" type="text/javascript"></script>

  

</body>

</html>
</body>

</html>
