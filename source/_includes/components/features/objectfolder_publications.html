<div class="section features-1">
  <div class="container">
    <div class="row text-left justify-content-left">
      <div class="col-lg-8">
        <h4>Publications</h4>
        <br />
      </div>
    </div>
    <ul>
      <li>
        <p>
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Gao_The_ObjectFolder_Benchmark_Multisensory_Learning_With_Neural_and_Real_Objects_CVPR_2023_paper.html"
            >The ObjectFolder Benchmark: Multisensory Learning
            with Neural and Real Objects</a
          >
        </p>
        <p>
          Ruohan Gao*, Yiming Dou*, Hao Li*, Tanmay Agarwal, Jeannette Bohg,
          Yunzhu Li, Li Fei-Fei and Jiajun Wu
        </p>
        <p>In Conference on Computer Vision and Pattern Recognition (CVPR), 2023</p>
      </li>
      <li>
        <p>
          <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Gao_ObjectFolder_2.0_A_Multisensory_Object_Dataset_for_Sim2Real_Transfer_CVPR_2022_paper.html"
            >ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real
            Transfer</a
          >
        </p>
        <p>
          Ruohan Gao*, Zilin Si*, Yen-Yu Chang*, Samuel Clarke, Jeannette Bohg,
          Li Fei-Fei, Wenzhen Yuan and Jiajun Wu
        </p>
        <p>
          In Conference on Computer Vision and Pattern Recognition (CVPR), 2022
        </p>
      </li>
      <li>
        <p>
          <a href="https://arxiv.org/abs/2109.07991"
            >ObjectFolder: A Dataset of Objects with Implicit Visual, Auditory,
            and Tactile Representations</a
          >
        </p>
        <p>
          Ruohan Gao, Yen-Yu Chang*, Shivani Mall*, Li Fei-Fei and Jiajun Wu
        </p>
        <p>In 5th Conference on Robot Learning (CoRL), 2021</p>
      </li>
    </ul>
  </div>
</div>
